name: Run Scraper and Deploy

on:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours at :00 (UTC)
  workflow_dispatch:

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      TZ: America/Chicago  # Set your timezone
    
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager requests beautifulsoup4 flask pillow

     
      - name: Install Google Chrome
        run: |
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt install -y ./google-chrome-stable_current_amd64.deb 

      - name: Run scraper
        run: |
          python -c "import os; print('Current directory contents:', os.listdir())"
          python scraper.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PYTHONUNBUFFERED: 1

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add -A
          git diff-index --quiet HEAD || git commit -m "Auto-update: $(date +'%Y-%m-%d %H:%M:%S')"
          git push